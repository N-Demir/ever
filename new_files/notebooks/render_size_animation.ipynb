{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amai/gaussian-splatting-merge\n",
      "4018\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "VERSION = 9\n",
    "os.environ[\"CC\"] = f\"/usr/bin/gcc-{VERSION}\"\n",
    "os.environ[\"CXX\"] = f\"/usr/bin/g++-{VERSION}\"\n",
    "import struct\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import mediapy\n",
    "\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(str(Path(os.path.abspath('')).parent))\n",
    "print(str(Path(os.path.abspath('')).parent))\n",
    "import torch\n",
    "from gaussian_renderer import GaussianModel, render\n",
    "from gaussian_renderer.eevr import splinerender\n",
    "from scene import Scene\n",
    "from scene.cameras import Camera, MiniCam\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from pyquaternion import Quaternion\n",
    "from scene.dataset_readers import ProjectionType\n",
    "\n",
    "dataset = \"london\"\n",
    "# path = \"berlin5\"\n",
    "# dataset = \"train\"\n",
    "path = \"train5\"\n",
    "eval_path = \"/home/amai/gaussian-splatting-merge/eval\"\n",
    "# eval_path = \"/home/amai/gaussian-splatting-merge/eval\"\n",
    "# output_path = Path(\"/data/popping_videos/ours0\") / dataset / \"images\"\n",
    "output_path = Path(f\"~/Videos/popping_paths/{path}/ours\")\n",
    "\n",
    "output_path = Path(f\"~/Videos/{dataset}/ours/\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "# f = open(f\"/data/video_paths/{dataset}/r1/path.path\", \"rb\")\n",
    "# f = open(f\"/home/amai/Videos/popping_paths/{path}.path\", \"rb\")\n",
    "f = open(f\"/home/amai/Videos/alameda.path\", \"rb\")\n",
    "# f = open(f\"smooth.path\", \"rb\")\n",
    "data = f.read()\n",
    "N = int.from_bytes(data[:4])\n",
    "camera_size = 11\n",
    "\n",
    "cameras = np.array(struct.unpack(f'>{N*camera_size}f', data[4:])).reshape(N, -1)\n",
    "full_data = struct.unpack(f'>i{N*camera_size}f', data)\n",
    "N = full_data[0]\n",
    "cameras = np.array(full_data[1:]).reshape(N, -1)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amai/gaussian-splatting-merge/eval/london\n",
      "Looking for config file in /home/amai/gaussian-splatting-merge/eval/london/cfg_args\n",
      "Config file found: /home/amai/gaussian-splatting-merge/eval/london/cfg_args\n"
     ]
    }
   ],
   "source": [
    "import shlex\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from arguments import ModelParams, PipelineParams, OptimizationParams\n",
    "\n",
    "def get_combined_args(args_cmdline):\n",
    "    cfgfile_string = \"Namespace()\"\n",
    "\n",
    "    try:\n",
    "        cfgfilepath = os.path.join(args_cmdline.model_path, \"cfg_args\")\n",
    "        print(\"Looking for config file in\", cfgfilepath)\n",
    "        with open(cfgfilepath) as cfg_file:\n",
    "            print(\"Config file found: {}\".format(cfgfilepath))\n",
    "            cfgfile_string = cfg_file.read()\n",
    "    except TypeError:\n",
    "        print(\"Config file not found at\")\n",
    "        pass\n",
    "    args_cfgfile = eval(cfgfile_string)\n",
    "\n",
    "    merged_dict = vars(args_cfgfile).copy()\n",
    "    for k, v in vars(args_cmdline).items():\n",
    "        if v != None:\n",
    "            merged_dict[k] = v\n",
    "    return Namespace(**merged_dict)\n",
    "\n",
    "\n",
    "parser = ArgumentParser(description=\"Testing script parameters\")\n",
    "model = ModelParams(parser, sentinel=True)\n",
    "pipeline = PipelineParams(parser)\n",
    "args = parser.parse_args(shlex.split(f\"-m {Path(eval_path) / dataset} --images images_2 -r 1\"))\n",
    "print(args.model_path)\n",
    "args = get_combined_args(args)\n",
    "model = model.extract(args)\n",
    "# model.source_path = str(Path(\"/data/nerf_synthetic\") / dataset)\n",
    "# model.source_path = str(Path(\"/data/nerf_datasets/tandt/\") / dataset)\n",
    "model.source_path = str(Path(\"/data/nerf_datasets/zipnerf_ud\") / dataset)\n",
    "\n",
    "model.max_opacity = 0.99\n",
    "\n",
    "pipeline = pipeline.extract(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| self.max_opacity: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model at iteration 30000\n",
      "Reading camera 1874/1874\n",
      "Loading Training Cameras\n",
      "Loaded Train Cameras: 1639\n",
      "Loaded Test Cameras: 235\n"
     ]
    }
   ],
   "source": [
    "gaussians = GaussianModel(model.sh_degree, model.max_opacity)\n",
    "scene = Scene(model, gaussians, load_iteration=-1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "refcam = scene.getTestCameras()[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:12, 15.52it/s]\n"
     ]
    }
   ],
   "source": [
    "background = torch.tensor([0, 0, 0], dtype=torch.float32, device=\"cuda\")\n",
    "# width = 1280\n",
    "# height = 720\n",
    "# width = 1200\n",
    "# height = 667\n",
    "width = refcam.image_width*4\n",
    "height = refcam.image_height*4\n",
    "image = torch.ones((3, height, width), dtype=float)\n",
    "frames = []\n",
    "for i, smod in tqdm(enumerate(torch.linspace(0.1, 1, 200))):\n",
    "    with torch.no_grad():\n",
    "        # rendering = renderer.render(view, pipeline, background)\n",
    "        rendering = splinerender(refcam, gaussians, pipeline, background, scaling_modifier=smod)[\"render\"]\n",
    "        byte_rendering = (rendering.permute(1, 2, 0).cpu().numpy()*255).clip(min=0, max=255).astype(np.uint8)\n",
    "        byte_rendering = cv2.resize(byte_rendering, (refcam.image_width, refcam.image_height), interpolation=cv2.INTER_AREA)\n",
    "    frames.append(byte_rendering)\n",
    "    # full_output_path = output_path / f\"{i:06d}.png\"\n",
    "    # imageio.imwrite(str(full_output_path), byte_rendering)\n",
    "    # plt.imshow(byte_rendering)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.stack(frames, axis=0)\n",
    "frames = np.concatenate([\n",
    "    frames,\n",
    "    torch.as_tensor(frames[-1]).unsqueeze(0).expand(50, -1, -1, -1).numpy(),\n",
    "    frames[::-1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediapy.show_video(frames, bps=100000000)\n",
    "mediapy.write_video(\"size_animation.mp4\", frames, bps=100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
