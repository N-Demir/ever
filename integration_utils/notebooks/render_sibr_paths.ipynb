{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CC\"] = \"/usr/bin/gcc-11\"\n",
    "os.environ[\"CXX\"] = \"/usr/bin/g++-11\"\n",
    "import struct\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(str(Path(os.path.abspath('')).parent))\n",
    "print(str(Path(os.path.abspath('')).parent))\n",
    "import torch\n",
    "from gaussian_renderer import GaussianModel, splinerender, render\n",
    "from scene import Scene\n",
    "from scene.cameras import Camera, MiniCam\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from pyquaternion import Quaternion\n",
    "from scene.dataset_readers import ProjectionType\n",
    "\n",
    "dataset = \"nyc\"\n",
    "path = \"train5\"\n",
    "eval_path = \"/home/gaussian-splatting-merge/eval.znf\"\n",
    "output_path = Path(f\"~/Videos/popping_paths/{path}/ours\")\n",
    "\n",
    "output_path = Path(f\"~/Videos/nyc1/ours/\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "f = open(f\"/home/Videos/nyc1.path\", \"rb\")\n",
    "data = f.read()\n",
    "N = int.from_bytes(data[:4])\n",
    "camera_size = 11\n",
    "\n",
    "cameras = np.array(struct.unpack(f'>{N*camera_size}f', data[4:])).reshape(N, -1)\n",
    "full_data = struct.unpack(f'>i{N*camera_size}f', data)\n",
    "N = full_data[0]\n",
    "cameras = np.array(full_data[1:]).reshape(N, -1)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shlex\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from arguments import ModelParams, PipelineParams, OptimizationParams\n",
    "\n",
    "def get_combined_args(args_cmdline):\n",
    "    cfgfile_string = \"Namespace()\"\n",
    "\n",
    "    try:\n",
    "        cfgfilepath = os.path.join(args_cmdline.model_path, \"cfg_args\")\n",
    "        print(\"Looking for config file in\", cfgfilepath)\n",
    "        with open(cfgfilepath) as cfg_file:\n",
    "            print(\"Config file found: {}\".format(cfgfilepath))\n",
    "            cfgfile_string = cfg_file.read()\n",
    "    except TypeError:\n",
    "        print(\"Config file not found at\")\n",
    "        pass\n",
    "    args_cfgfile = eval(cfgfile_string)\n",
    "\n",
    "    merged_dict = vars(args_cfgfile).copy()\n",
    "    for k, v in vars(args_cmdline).items():\n",
    "        if v != None:\n",
    "            merged_dict[k] = v\n",
    "    return Namespace(**merged_dict)\n",
    "\n",
    "\n",
    "parser = ArgumentParser(description=\"Testing script parameters\")\n",
    "model = ModelParams(parser, sentinel=True)\n",
    "pipeline = PipelineParams(parser)\n",
    "args = parser.parse_args(shlex.split(f\"-m {Path(eval_path) / dataset} --images images_2 -r 1\"))\n",
    "print(args.model_path)\n",
    "args = get_combined_args(args)\n",
    "model = model.extract(args)\n",
    "model.source_path = str(Path(\"/data/nerf_datasets/zipnerf_ud\") / dataset)\n",
    "\n",
    "model.max_opacity = 0.99\n",
    "\n",
    "pipeline = pipeline.extract(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussians = GaussianModel(model.sh_degree, model.max_opacity)\n",
    "scene = Scene(model, gaussians, load_iteration=-1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "refcam = scene.getTrainCameras()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaussian_renderer.fast_renderer import FastRenderer\n",
    "\n",
    "renderer = FastRenderer(refcam, gaussians, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = torch.tensor([0, 0, 0], dtype=torch.float32, device=\"cuda\")\n",
    "width = refcam.image_width\n",
    "height = refcam.image_height\n",
    "image = torch.ones((3, height, width), dtype=float)\n",
    "for i in tqdm(range(N)):\n",
    "    T = cameras[i, :3]\n",
    "    # xyzw\n",
    "    quat = cameras[i, 3:7]\n",
    "    R = Quaternion(x=quat[0], y=quat[1], z=quat[2], w=quat[3]).transformation_matrix\n",
    "    R[:3, 3] = T\n",
    "    transf = np.linalg.inv(R).T\n",
    "    transf[:, 1] = -transf[:, 1]\n",
    "    transf[:, 2] = -transf[:, 2]\n",
    "\n",
    "    fovy = cameras[i, -4]\n",
    "    fovx = cameras[i, -3]\n",
    "    fovy = refcam.FoVy\n",
    "    fovx = refcam.FoVx\n",
    "    znear = cameras[i, -2]\n",
    "    zfar = cameras[i, -1]\n",
    "    world_view_transform = torch.as_tensor(transf).float()\n",
    "    full_proj_transform = torch.as_tensor(transf).float()\n",
    "    view = MiniCam(width, height, fovy, fovx, znear, zfar, world_view_transform, full_proj_transform)\n",
    "    view.model = ProjectionType.PERSPECTIVE\n",
    "    with torch.no_grad():\n",
    "        renderer.set_camera(view)\n",
    "        rendering = renderer.render(view, pipeline, background)\n",
    "        byte_rendering = (rendering.permute(1, 2, 0).cpu().numpy()*255).clip(min=0, max=255).astype(np.uint8)\n",
    "    full_output_path = output_path / f\"{i:06d}.png\"\n",
    "    imageio.imwrite(str(full_output_path), byte_rendering)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
